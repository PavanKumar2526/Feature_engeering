{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp2XoHiyGJHRnxwEdbahf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavanKumar2526/Feature_engeering/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. A parameter is any quantity of a statistical population that summarizes or describes an aspect of the population, such as a mean or a standard deviation. It represents the true value calculated from the full population, as opposed to a statistic which is an estimated measurement based on a sample."
      ],
      "metadata": {
        "id": "o4iWuv31ouN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.  Correlation is any statistical relationship, whether causal or not, between two random variables or bivariate data. It indicates the degree to which a pair of variables are linearly related.\n",
        "\n",
        "## Negative correlation, or inverse correlation, describes a situation where, as one variable increases in value, the other decreases. It is often represented with a value of -1, showing that while x (the first variable) gains value, y (the second variable) decreases in value."
      ],
      "metadata": {
        "id": "1ESHFTKro6_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Machine learning is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data. The main components of machine learning are:\n",
        "Representation: How to represent knowledge (e.g., decision trees, neural networks)\n",
        "Evaluation: How to evaluate candidate programs (e.g., accuracy, squared error)\n",
        "Optimization: How candidate programs are generated (e.g., combinatorial optimization\n"
      ],
      "metadata": {
        "id": "n7VqlbJGpCps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Loss is a value that represents the summation of errors in a model8. A high loss indicates that the model is not performing well, while a lower loss suggests better performance8. The loss helps determine the model's quality by measuring how well it approximates the output when given new data"
      ],
      "metadata": {
        "id": "pQ5amHfspb5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Continuous variables are numerical variables that can take on any value within a certain range. Categorical variables are variables that can take on one of a limited number of possible values or categories."
      ],
      "metadata": {
        "id": "mSSWqbWeph-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Common techniques for handling categorical variables in Machine Learning include:\n",
        "#> One-Hot Encoding: Creates binary columns for each category\n",
        "#> Label Encoding: Assigns a unique integer to each category\n",
        "#> Ordinal Encoding: Assigns integers based on a meaningful order of categories\n",
        "#> Count Encoding: Assigns values based on the frequency of each category.\n"
      ],
      "metadata": {
        "id": "ewU_eGrMpmdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Training a dataset involves feeding data to a model so it can learn the underlying patterns. Testing involves evaluating the model's performance on unseen data to assess its generalization ability."
      ],
      "metadata": {
        "id": "zO0gNCfbp_JU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6aytVWEUpzKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. sklearn.preprocessing is a module in scikit-learn that provides functions for data preprocessing, including scaling, normalization, and encoding."
      ],
      "metadata": {
        "id": "nXuEeANKqFfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. A test set is a subset of the original dataset used for evaluating the final performance of a trained model. It contains data that the model has not seen during training, providing an unbiased evaluation of the model's performance."
      ],
      "metadata": {
        "id": "U5qRl6rrqKYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. In Python, we can split data for model fitting using the train_test_split function from sklearn.model_selection. For example:\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n"
      ],
      "metadata": {
        "id": "hkYxnw9rqRJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. Exploratory Data Analysis (EDA) is performed before fitting a model to understand the data's characteristics, identify patterns, detect outliers, and determine appropriate preprocessing steps11. This helps in selecting suitable algorithms and features for the model."
      ],
      "metadata": {
        "id": "alk3FXN8qeiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. Correlation is any statistical relationship between two random variables or bivariate data. It measures the degree to which two variables are linearly related."
      ],
      "metadata": {
        "id": "oAjrJ5nNqi0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13.  Negative correlation means that as one variable increases, the other decreases. It's often represented with a value of -1, indicating an inverse relationship between the variables."
      ],
      "metadata": {
        "id": "jrLU_TPLqnSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14. In Python, you can find correlation between variables using methods like:\n",
        "import pandas as pd\n",
        "df.corr()  # Pearson correlation\n",
        "df.corr(method='spearman')  # Spearman correlation\n"
      ],
      "metadata": {
        "id": "5O701CZeqqff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. Causation indicates that one event causes another. The key difference between correlation and causation is that correlation only identifies a relationship, while causation implies a direct cause-and-effect link. For example, there might be a correlation between ice cream sales and sunburn cases, but ice cream doesn't cause sunburn - both are likely caused by hot weather."
      ],
      "metadata": {
        "id": "S8Qnpbbrq2pR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. An optimizer is an algorithm used to minimize the loss function during model training. Some common optimizers include:\n",
        "##> Stochastic Gradient Descent (SGD): Simple and computationally efficient\n",
        "##> Adam: Efficient and straightforward to implement, good for large datasets\n",
        "##> RMSProp: Effective for non-stationary objectives\n",
        "##> Adagrad: Adaptive learning rate per parameter, effective for sparse data.\n"
      ],
      "metadata": {
        "id": "1w6sWbUJq7bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17. sklearn.linear_model is a module in scikit-learn that provides various linear models, including linear regression, logistic regression, and others."
      ],
      "metadata": {
        "id": "tO8NCAkPrQvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18.  model.fit() is used to train a machine learning model. It takes the feature matrix X and target vector y as arguments:\n",
        "#model.fit(X, y)\n"
      ],
      "metadata": {
        "id": "XPv-5HA0rWgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19. model.predict() is used to make predictions using a trained model. It takes the feature matrix X as an argument:\n",
        "#predictions = model.predict(X)\n"
      ],
      "metadata": {
        "id": "wvb4C9hyrZWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20. Continuous variables are numerical variables that can take on any value within a certain range. Categorical variables are variables that can take on one of a limited number of possible values or categories."
      ],
      "metadata": {
        "id": "x-gQgd_3rb0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21. Feature scaling is a technique to standardize the independent features in a dataset to a fixed range. It helps in:\n",
        "#> Improving algorithm performance\n",
        "#> Preventing numerical instability\n",
        "#> Ensuring fair contribution of all features.\n"
      ],
      "metadata": {
        "id": "gBROoBdnrdqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22. In Python, we can perform scaling using sklearn.preprocessing:\n",
        "##from sklearn.preprocessing import StandardScaler\n",
        "##scaler = StandardScaler()\n",
        "##X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "SwVUwG3BriNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#23. sklearn.preprocessing is a module in scikit-learn that provides functions for data preprocessing, including scaling, normalization, and encoding."
      ],
      "metadata": {
        "id": "QQ_hZv-DrkxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#24. In Python, we can split data for model fitting using the train_test_split function:\n",
        "##from sklearn.model_selection import train_test_split\n",
        "##X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n"
      ],
      "metadata": {
        "id": "glnaa2aKrmzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25.  Data encoding refers to converting categorical variables into numerical representations that can be understood by machine learning algorithms. Common techniques include one-hot encoding, label encoding, and ordinal encoding. This process is crucial for preparing categorical data for use in machine learning algorithms that typically require numerical input."
      ],
      "metadata": {
        "id": "72LUaPrWroLH"
      }
    }
  ]
}